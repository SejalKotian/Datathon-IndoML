{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oErdUfPA4vcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf0bc92-b997-4207-93fd-72ff060c4e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ-BN7DB5DKv"
      },
      "outputs": [],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJztSkuo5MHK"
      },
      "outputs": [],
      "source": [
        "train_path=\"/content/drive/MyDrive/datathonindoml-2022/tif/train\"\n",
        "val_path=\"/content/drive/MyDrive/datathonindoml-2022/tif/val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJM2JXAf5Se2"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfgct3ET5T6t"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input,Lambda,Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout, Input, Conv2D, MaxPooling2D, Flatten, Lambda\n",
        "from keras.models import Model, Sequential\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqOUbvB75ZH9"
      },
      "outputs": [],
      "source": [
        "train_labels=\"/content/drive/MyDrive/datathonindoml-2022/train_labels.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSdvK3566FJy"
      },
      "outputs": [],
      "source": [
        "train_labels_df=pd.read_csv(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zAW3_zB6J0-",
        "outputId": "61698af1-c620-4be7-cc35-7223543026c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 15s 0us/step\n",
            "80150528/80134624 [==============================] - 15s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg=VGG19(input_shape=(224,224,3),weights='imagenet',include_top=False)\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgVfqPtz7weE"
      },
      "outputs": [],
      "source": [
        "folders=glob('/content/drive/MyDrive/datathonindoml-2022/tif/train/*')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d57PBtL77En",
        "outputId": "2555014f-b668-4b4d-dbdf-d13da2f46d75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/datathonindoml-2022/tif/train/0',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/1',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/2',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/3',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/4',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/5',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/6',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/7',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/8',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/9',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/10',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/11',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/12',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/13',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/14',\n",
              " '/content/drive/MyDrive/datathonindoml-2022/tif/train/15']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uECknhK_7-2o"
      },
      "outputs": [],
      "source": [
        "#layers\n",
        "# our layers - you can add more if you want\n",
        "x = Flatten()(vgg.output)\n",
        "#making predictions\n",
        "p = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=vgg.input, outputs=p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c91bi85o8RQ2",
        "outputId": "3a22f60b-1253-416d-bba0-287cf1e79c3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                401424    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,425,808\n",
            "Trainable params: 401,424\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7JiqWHE8UZt"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer= 'adam',\n",
        "             metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jmogcb8O4Klq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85GO0mns8Zgo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard \n",
        "callback = EarlyStopping(monitor='loss', patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1B9_1IB8fLH"
      },
      "outputs": [],
      "source": [
        "#Did not apply Data Augmentation here\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen= ImageDataGenerator(rescale=1./255)\n",
        "test_datagen= ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj_Jalpl8k6Y",
        "outputId": "3ff6cb3e-9d3f-46ba-b5e3-1ac763f448bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12794 images belonging to 16 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set =  train_datagen.flow_from_directory('/content/drive/MyDrive/datathonindoml-2022/tif/train',\n",
        "                                                 target_size=(224,224),\n",
        "                                                 batch_size=64,\n",
        "                                                 class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlNmaZy98npD",
        "outputId": "b38ee44c-0d19-45ad-9dce-2f4436ff77f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3206 images belonging to 16 classes.\n"
          ]
        }
      ],
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "testing_set = datagen.flow_from_directory('/content/drive/MyDrive/datathonindoml-2022/tif/val',\n",
        "                                        target_size=(224,224),\n",
        "                                        batch_size=64,\n",
        "                                        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juxyEoUp8rTs",
        "outputId": "76eb0675-7be2-4db7-f43c-845384be7bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "50/50 [==============================] - 2674s 54s/step - loss: 2.0693 - accuracy: 0.4112 - val_loss: 1.4721 - val_accuracy: 0.5597\n",
            "Epoch 2/10\n",
            "50/50 [==============================] - 1025s 21s/step - loss: 1.3391 - accuracy: 0.6069 - val_loss: 1.3784 - val_accuracy: 0.5872\n",
            "Epoch 3/10\n",
            "50/50 [==============================] - 763s 15s/step - loss: 1.1487 - accuracy: 0.6662 - val_loss: 1.3116 - val_accuracy: 0.6069\n",
            "Epoch 4/10\n",
            "50/50 [==============================] - 590s 12s/step - loss: 1.0927 - accuracy: 0.6787 - val_loss: 1.3155 - val_accuracy: 0.6100\n",
            "Epoch 5/10\n",
            "50/50 [==============================] - 439s 9s/step - loss: 1.0141 - accuracy: 0.6925 - val_loss: 1.2561 - val_accuracy: 0.6350\n",
            "Epoch 6/10\n",
            "50/50 [==============================] - 327s 7s/step - loss: 0.9439 - accuracy: 0.7175 - val_loss: 1.2013 - val_accuracy: 0.6500\n",
            "Epoch 7/10\n",
            "50/50 [==============================] - 239s 5s/step - loss: 0.8936 - accuracy: 0.7317 - val_loss: 1.1453 - val_accuracy: 0.6622\n",
            "Epoch 8/10\n",
            "50/50 [==============================] - 201s 4s/step - loss: 0.8398 - accuracy: 0.7456 - val_loss: 1.2411 - val_accuracy: 0.6284\n",
            "Epoch 9/10\n",
            "50/50 [==============================] - 148s 3s/step - loss: 0.8159 - accuracy: 0.7473 - val_loss: 1.1890 - val_accuracy: 0.6466\n",
            "Epoch 10/10\n",
            "50/50 [==============================] - 130s 3s/step - loss: 0.7784 - accuracy: 0.7725 - val_loss: 1.1584 - val_accuracy: 0.6622\n",
            "model saved to disk\n"
          ]
        }
      ],
      "source": [
        "r= model.fit(training_set,\n",
        "             validation_data= testing_set,\n",
        "             epochs=10,\n",
        "             steps_per_epoch= 50,\n",
        "             validation_steps=50,\n",
        "             callbacks= [callback]\n",
        "             )\n",
        "model.save_weights(\"model_vgg19_2\")\n",
        "print(\"model saved to disk\")\n",
        "model.save(\"my_model_vgg19\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}